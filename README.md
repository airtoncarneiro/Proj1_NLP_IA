



![elem3](https://user-images.githubusercontent.com/104634692/169033139-31b70a2d-d302-4150-b6ca-723dd636aa3c.png)



# Primeiro Projeto do Bootcamp do Instituto Atl√¢ntico 


### Desenvolvido pelos alunos do Squad2:
Airton, √çcaro e Leandro


## O Projeto

Para executar o projeto clone o reposit√≥rio e use o pipinstall com o arquivo requirements.
Para execut√°-lo, abrir o main.py e rodar.
O projeto est√° todo customiz√°vel e adapt√°vel. A quantidade de n√≥s, quantas palavras vizinhas, leitura de quaisquer arquivos com extens√£o .PDF.
Tamb√©m foi usado classe (obj), m√≥dulos Python para chamadas. Todo arquivo Python possui docstring explicando os par√¢metros de entrada e sa√≠da dos m√©todos e fun√ß√µes. Tamb√©m est√£o explicitamente informados os tipos (Data Type) de cada vari√°vel nas fun√ß√µes/classes.<br>
## Introdu√ß√£o

Projeto criado com o objetivo de apresentar, com base em NLP, uma vis√£o geral do hist√≥rico de um paciente sem a necessidade de analisar documento por documento referentes a hist√≥rico de exames, consultas e procedimentos.



### Sum√°rio da solu√ß√£o

1. [Dataset](#section01)
   
2. [Pr√©-processamento dos dados](#section02)
  
3. [Lematiza√ß√£o](#section03)

4. Determinar com base nos resultados da lematiza√ß√£o:

    4.1 Term Frequency<br>
    4.2 Document Frequency<br>
    4.3 Inverse Document Frequency<br>
    4.4 TF-IDF<br>
    4.5 ùëáùêπ ‚àí ùêºùê∑ùêπ = ùêºùê∑ùêπ * ùëáùêπ<br>
 5. Gerar um arquivo csv que possui todas as palavras de todos os documentos na primeira coluna
 6. [Resultado em Nuvem de palavras](#section04)
 7. [T√≥picos de Aux√≠lio](#section05)
   


<a id='section01'></a>
### Dataset
Como base dados foram utilizados 3 documentos com hist√≥rico de consultas no formato pdf de um paciente.

<a id='section02'></a>
### Pr√©-processamento dos dados
Para os dados foram aplicados processamento como tokeniza√ß√£o e remo√ß√£o de stop words e transformar os caracteres todos em min√∫sculos.

<a id='section03'></a>
### Lematiza√ß√£o
Tendo os dados j√° processados realizou-se a lematiza√ß√£o com a biblioteca Stanza.

<a id='section04'></a>
### Resultado em nuvem de palavras

![wordcloud](./img/wordcloud2.png)

<a id='section05'></a>
### T√≥picos de Aux√≠lio


**T√≥picos de Aux√≠lio**
https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-worlddataset-796d339a4089

**Informa√ß√µes sobre as m√©tricas utilizadas**
https://www.kaggle.com/arthurtok/ghastly-network-and-d3-js-force-directed-graphs

**Atividade determina√ß√£o da nuvem de palavras**
http://andrewtrick.com/stormlight_network.html
