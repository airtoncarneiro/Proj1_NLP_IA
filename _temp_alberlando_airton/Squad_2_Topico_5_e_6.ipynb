{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Y8BjQ6Rona9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from heapq import nlargest\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import re, string\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf9JuFr1yQ0A",
        "outputId": "e2f9c615-d1f6-475a-8a11-f8cdf9dd9b17"
      },
      "outputs": [],
      "source": [
        "# Criando Sentenças\n",
        "sentenca = []\n",
        "with open('3student.txt') as file_data:\n",
        "  for i in file_data:\n",
        "    sentenca.append( sent_tokenize(i) )\n",
        "\n",
        "# Colocando em minúsculo\n",
        "lower = [ j.lower() for i in sentenca for j in i ]\n",
        "\n",
        "# Fazendo limpeza\n",
        "clean = []\n",
        "for i in lower:\n",
        "    alpha = re.sub( r'[0-9]+', '', i )\n",
        "    clean.append( alpha.translate( str.maketrans( '', '', string.punctuation ) ).strip() )\n",
        "\n",
        "# Tokenização\n",
        "tokenized = [ x for x in [ word_tokenize(i) for i in clean ] if x != [] ]\n",
        "\n",
        "# Juntando lista de palavras\n",
        "chain = list(chain(*tokenized))\n",
        "\n",
        "# Retirando as Stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "no_stopwords = [ i for i in chain if i not in stopwords ]\n",
        "\n",
        "# Lematização\n",
        "wnet = WordNetLemmatizer()\n",
        "lem = [ wnet.lemmatize(lyr) for lyr in no_stopwords ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YejxchKxyQ43"
      },
      "outputs": [],
      "source": [
        "# Criando listas simulando 3 documentos\n",
        "lista_dividida = np.array_split(lem, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtWZaAc6mKog",
        "outputId": "c3b00530-b693-4afe-fb9e-f23799120161"
      },
      "outputs": [],
      "source": [
        "for i in lista_dividida:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs5yNjpRXN-v"
      },
      "outputs": [],
      "source": [
        "# IDF\n",
        "temp, lis = {}, []\n",
        "for i in set(lem):\n",
        "  for k in range(len(lista_dividida)):\n",
        "    if i in lista_dividida[k]:\n",
        "      lis.append(i)\n",
        "      temp[i] = len(lis)\n",
        "  lis.clear()\n",
        "\n",
        "idf = {}\n",
        "for i, j in temp.items():\n",
        "  idf[i] = math.log10(len(lista_dividida)/float(j))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ji1GaLt9yRYU",
        "outputId": "25ac428b-da93-4611-c81f-b530e7b102a3"
      },
      "outputs": [],
      "source": [
        "# Criando DataFrame de TF, DF, IDF e TF-IDF\n",
        "df_raw = pd.DataFrame(lem, columns=['words'])\n",
        "df = df_raw.value_counts(normalize=True).rename_axis('words').reset_index(name='tf')\n",
        "df_df = df_raw.value_counts().rename_axis('words').reset_index(name='df')\n",
        "df = df.merge(df_df, how='left', left_on='words', right_on='words')\n",
        "df_idf = pd.DataFrame(idf.items(), columns = ['words', 'idf'])\n",
        "df = df.merge(df_idf, how='left', left_on='words', right_on='words')\n",
        "df['tf-idf'] = df.idf * df.tf\n",
        "df.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OEm_KSfeo4yr"
      },
      "outputs": [],
      "source": [
        "dicionario = {\n",
        "  'brincar': ['feliz', 'escada', 'policia', 'mundo', 'parede', 'feliz'],\n",
        "  'correr': ['rua', 'parque', 'escada', 'noiva', 'aliança', 'mãe'],\n",
        "  'chutar': ['ladrao', 'parede', 'irmao', 'mundo', 'parque', 'feliz'],\n",
        "  'amar': ['noiva', 'esposa', 'parque', 'policia', 'esposa', 'rua'],\n",
        "  'gostar': ['noiva', 'esposa', 'irmao', 'mundo', 'parede', 'porta'],\n",
        "  'destruir': ['mundo', 'parede', 'porta', 'noiva', 'aliança', 'mãe'],\n",
        "  'noivar': ['noiva', 'aliança', 'mãe', 'mundo', 'parque', 'feliz'],\n",
        "  'matar': ['policia', 'ladrao', 'bandido', 'noiva', 'aliança', 'mãe'],\n",
        "  'cair': ['rua', 'porta', 'escada', 'mundo', 'parque', 'feliz'],\n",
        "  'morrer': ['policia', 'esposa', 'rua', 'mundo', 'parque', 'feliz'],\n",
        "  'viver': ['mundo', 'parque', 'feliz', 'noiva', 'aliança', 'mãe'],\n",
        "  'anoitecer' : ['rua', 'parque', 'irmao', 'mundo', 'parede', 'porta']\n",
        "}\n",
        "\n",
        "# TF-IDF\n",
        "tamanho = {\n",
        "    'brincar': 0.90,\n",
        "    'correr': 0.75,\n",
        "    'chutar': 0.60,\n",
        "    'amar': 0.45,\n",
        "    'gostar': 0.30,\n",
        "    'destruir': 0.11,\n",
        "    'noivar': 0.10,\n",
        "    'matar': 0.09,\n",
        "    'cair': 0.08,\n",
        "    'morrer': 0.07,\n",
        "    'viver': 0.06,\n",
        "    'anoitecer' : 0.05\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "VJiGYPa4XBF1",
        "outputId": "d916c854-95b3-4b11-ded7-15d1fb38daef"
      },
      "outputs": [],
      "source": [
        "# Segundo questão tem que pegar 5 maiores TF-IDF para servir de Words\n",
        "words = nlargest( 5, tamanho, key = tamanho.get )\n",
        "edges = [ (i, j[k]) for i, j in dicionario.items() if i in words for k in range(len(j)) ]\n",
        "\n",
        "# Setando a variável do gráfico\n",
        "plt.subplots(figsize=(12,6))\n",
        "G = nx.Graph()\n",
        "\n",
        "# Nodes and Edges\n",
        "G.add_nodes_from( words )\n",
        "G.add_edges_from( edges )\n",
        "\n",
        "# Criando node_color e node_size personalizados nos dados\n",
        "node_color = [ 'orange' if i in words else 'skyblue' for i in G ]\n",
        "node_size = [ int(tamanho[node]*2000) if node in words else 350 for node in G ]\n",
        "\n",
        "# Construindo Gráfico:\n",
        "nx.draw_kamada_kawai( G, with_labels=True, width=3, node_size=node_size, node_color=node_color, edge_color=\"gray\", style=\"solid\" )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZuU61YMrE5p"
      },
      "outputs": [],
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "nx.draw_kamada_kawai( G, with_labels=True, width=3, node_size=node_size, node_color=node_color, edge_color=\"gray\", style=\"solid\" )\n",
        "pos = nx.kamada_kawai_layout(G)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Squad_2_Topico_5_e_6.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0c715bfb9df34512991fce63625278dda66c51e5dbc1dbfc046f1bef2d1eb027"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('IAtlantico')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
